{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "from distutils.util import strtobool\n",
    "import collections\n",
    "import numpy as np\n",
    "import gym\n",
    "import json\n",
    "from gym.wrappers import TimeLimit, Monitor\n",
    "from gym.spaces import Discrete, Box, MultiBinary, MultiDiscrete, Space\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from gym import spaces\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import math\n",
    "\n",
    "from itertools import count\n",
    "\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_x(X):\n",
    "    for i,data in enumerate(X):\n",
    "        middle_point = int(len(data)/2)\n",
    "        x = data[:middle_point]\n",
    "        y = data[middle_point:]\n",
    "        sorted_xy = np.asarray([[a,x] for a,x in sorted(zip(data[:middle_point],data[middle_point:]))])\n",
    "        new_data = np.concatenate((sorted_xy[:,0], sorted_xy[:,1]), axis=None)\n",
    "        X[i] = new_data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DISCRETE_ACTIONS = 5 # Number of networks\n",
    "\n",
    "class NAS_Env(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, data_path, reward_penalty=0.01, naction_ending=5, step_sampling=False, taboo_actions=0):\n",
    "        super(NAS_Env, self).__init__()\n",
    "    # Define action and observation space\n",
    "    # They must be gym.spaces objects\n",
    "    # Example when using discrete actions:\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.X_train, self.y_train, self.X_test, self.y_test, self.r_train, self.r_test = self.load_data()\n",
    "    \n",
    "        self.reward_range = (-1,1)\n",
    "        self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)\n",
    "        self.observation_space = spaces.Box(low=-5, high=5, shape=(2, 80), dtype=np.float16)\n",
    "        \n",
    "        self.reward_penalty = reward_penalty\n",
    "        self.naction_ending = naction_ending\n",
    "        self.step_sampling = step_sampling\n",
    "        \n",
    "        self.set_train_mode()\n",
    "        \n",
    "        self.current_dataset_id  = 0\n",
    "        \n",
    "        self.set_current_dataset()\n",
    "        \n",
    "        self.current_mask = []\n",
    "        self.current_step = 1\n",
    "        self.current_observation = self.get_observation()\n",
    "        #print(\"Current observation\", self.current_observation)\n",
    "        \n",
    "        self.history_action = []\n",
    "        self.history_rewards = []\n",
    "        self.history_max_possible_rewards = []\n",
    "        \n",
    "        self.taboo_actions = taboo_actions\n",
    "        self.available_actions = list(range(N_DISCRETE_ACTIONS))\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def set_train_mode(self):\n",
    "        \n",
    "        self.datasets = self.X_train\n",
    "        self.ys = self.y_train\n",
    "        self.rewards = self.r_train\n",
    "        \n",
    "    def set_test_mode(self):\n",
    "        \n",
    "        self.datasets = self.X_test\n",
    "        self.ys = self.y_test\n",
    "        self.rewards = self.r_test \n",
    "        \n",
    "    def set_current_dataset(self):\n",
    "        \n",
    "        self.current_dataset = self.datasets[self.current_dataset_id].reshape((2,80))\n",
    "        self.current_ys = self.ys[self.current_dataset_id]\n",
    "        self.current_rewards = self.rewards[self.current_dataset_id]   \n",
    "         \n",
    "    def step(self, action):\n",
    "        # Assumes action is valid\n",
    "        \n",
    "        if action not in self.available_actions:\n",
    "            print(\"INVALID ACTION\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        #print(\"Action:\",action)\n",
    "        \n",
    "        done = (self.current_step >= self.naction_ending and len(np.unique(\n",
    "            self.history_action[-self.naction_ending:])) == 1) or (self.current_step == self.current_dataset.shape[1] - 1)\n",
    "        \n",
    "        \n",
    "        full_reward = self.current_rewards[action]\n",
    "        discounted_reward = full_reward * np.exp(-self.current_step * self.reward_penalty)\n",
    "        \n",
    "        max_possible_reward = max(self.current_rewards)\n",
    "        discounted_max_possible_reward = max_possible_reward * np.exp(-self.current_step * self.reward_penalty)\n",
    "        \n",
    "        self.history_action.append(action)\n",
    "        self.history_rewards.append(discounted_reward)\n",
    "        self.history_max_possible_rewards.append(discounted_max_possible_reward)\n",
    "        \n",
    "        \n",
    "        self.current_step +=1\n",
    "        #print(self.current_step)\n",
    "        self.current_observation = self.get_observation()\n",
    "        #print(\"Current observation\", self.current_observation)\n",
    "        \n",
    "        return self.current_observation, discounted_reward, done, \"\"\n",
    "        \n",
    "         \n",
    "    def get_observation(self):\n",
    "        \n",
    "        \n",
    "         # Mask\n",
    "        step_mask = np.zeros(self.current_dataset.shape[1])\n",
    "        #step_mask[:self.current_step] = 1.0\n",
    "        \n",
    "        if self.step_sampling:\n",
    "            available_idxs = list(set(range(len(step_mask))).difference(set(self.current_mask)))\n",
    "            chosen_idx = np.random.choice(available_idxs)\n",
    "            self.current_mask.append(chosen_idx)\n",
    "        else:\n",
    "            self.current_mask = list(range(self.current_step))\n",
    "        \n",
    "        step_mask[self.current_mask] = 1.0\n",
    "        \n",
    "        new_obs = copy.deepcopy(self.current_dataset)\n",
    "        new_obs[0, :] = new_obs[0,:] * step_mask\n",
    "        new_obs[1, :] = new_obs[1,:] * step_mask\n",
    "        return new_obs\n",
    "         \n",
    "    # Execute one time step within the environment\n",
    "    \n",
    "    def reset(self, train = False):\n",
    "        \n",
    "        if train == True:\n",
    "            self.set_train_mode()\n",
    "        else:\n",
    "            self.set_test_mode()\n",
    "            \n",
    "        self.current_dataset_id  = random.randint(0, self.datasets.shape[0]-1)\n",
    "        self.set_current_dataset()\n",
    "        \n",
    "        self.current_mask = []\n",
    "        self.current_step = 1\n",
    "        self.current_observation = self.get_observation()\n",
    "        \n",
    "        self.history_action = []\n",
    "        self.history_rewards = []\n",
    "        self.history_max_possible_rewards = []\n",
    "        \n",
    "        # Set taboo actions if applicable\n",
    "        if isinstance(self.taboo_actions, int):\n",
    "            if self.taboo_actions > 0:\n",
    "                self.available_actions = sorted(list(np.random.choice(np.arange(N_DISCRETE_ACTIONS), size=N_DISCRETE_ACTIONS-self.taboo_actions, replace=False)))\n",
    "            else:\n",
    "                self.available_actions = list(range(N_DISCRETE_ACTIONS))\n",
    "        elif isinstance(self.taboo_actions, list):\n",
    "            assert len(set(self.taboo_actions)) <= N_DISCRETE_ACTIONS\n",
    "            self.available_actions = sorted(self.taboo_actions)\n",
    "        \n",
    "        \n",
    "  \n",
    "        \n",
    "    # Reset the state of the environment to an initial state\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        print(\"lol\")\n",
    "    # Render the environment to the screen\n",
    "    \n",
    "    def load_data(self):\n",
    "        \n",
    "        with open(self.data_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        # # keep only winning networks\n",
    "        X, y, r = [], [], []\n",
    "        n_networks = len(np.unique(data[\"actions\"]))\n",
    "        n_func = len(data[\"states\"]) // n_networks\n",
    "        # # print(n_networks, n_func)\n",
    "        for f_i in range(n_func):\n",
    "            scores_i = []\n",
    "            actions_i = []\n",
    "            for n_i in range(n_networks):\n",
    "                i = f_i * n_networks + n_i\n",
    "                scores_i.append(data[\"scores\"][i])\n",
    "                actions_i.append(data[\"actions\"][i])\n",
    "            X.append(data[\"states\"][i])\n",
    "            y.append(actions_i)\n",
    "            r.append(scores_i)\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        r = np.array(r)\n",
    "        \n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "        print(r.shape)\n",
    "        # fix action ordering\n",
    "#         print(y)\n",
    "        idx_order = np.argsort(y[0])\n",
    "        y = y[:, idx_order]\n",
    "        r = r[:, idx_order]\n",
    "        idxs = np.arange(X.shape[0])\n",
    "        test_split = int(0.33 * len(idxs))\n",
    "        np.random.shuffle(idxs)\n",
    "        \n",
    "        idxs_train = idxs[:-test_split]\n",
    "        idxs_test = idxs[-test_split:]\n",
    "        \n",
    "        X_train = X[idxs_train]\n",
    "        y_train = y[idxs_train]\n",
    "        r_train = r[idxs_train]\n",
    "        \n",
    "        X_test = X[idxs_test]\n",
    "        y_test = y[idxs_test]\n",
    "        r_test = r[idxs_test]\n",
    "        \n",
    "        return sort_by_x(X_train), y_train, sort_by_x(X_test), y_test, r_train, r_test \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 160)\n",
      "(900, 5)\n",
      "(900, 5)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"polynome_ready_for_training.json\"\n",
    "SHUFFLE_SAMPLES = False\n",
    "\n",
    "env = NAS_Env(data_path, reward_penalty=0.01, naction_ending=5, step_sampling=SHUFFLE_SAMPLES, taboo_actions=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.available_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([219, 203, 164,  14,   3], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(np.argmax(env.r_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training True best network distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training True best network distribution\")\n",
    "plt.bar(x = list(range(5)), height= np.bincount(np.argmax(env.r_train, axis=1))/env.r_train.shape[0])\n",
    "plt.title(\"Best network distribution (training set)\")\n",
    "plt.xlabel(\"Architecture index\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./figures/arch_distribution-train.pdf\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training True best network distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training True best network distribution\")\n",
    "plt.bar(x = list(range(5)), height= np.bincount(np.argmax(env.r_test, axis=1))/env.r_test.shape[0])\n",
    "plt.title(\"Best network distribution (test set)\")\n",
    "plt.xlabel(\"Architecture index\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./figures/arch_distribution-test.pdf\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        else:\n",
    "            return False\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        return True\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.memory = []\n",
    "        self.position = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(env.observation_space.shape[0]* env.observation_space.shape[1], 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, env.action_space.n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (fc1): Linear(in_features=160, out_features=64, bias=True)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net = DQN(env)\n",
    "target_net = DQN(env)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps_done = 0\n",
    "\n",
    "TARGET_UPDATE = 5\n",
    "BATCH_SIZE = 20\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "\n",
    "def get_action(state):\n",
    "    \n",
    "    global total_steps_done\n",
    "    sample = random.random()\n",
    "    \n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * total_steps_done / EPS_DECAY)\n",
    "    \n",
    "    total_steps_done += 1\n",
    "    \n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            policy_net.eval()\n",
    "            actions = policy_net(state)\n",
    "            policy_net.train()\n",
    "            \n",
    "            ranking = torch.argsort(actions, descending=True)[0]\n",
    "            for action_candidate in ranking:\n",
    "                if action_candidate in env.available_actions:\n",
    "                    return torch.tensor(action_candidate)\n",
    "\n",
    "                \n",
    "            \n",
    "#             choice = torch.argmax(actions)\n",
    "#             if choice not in env.available_actions:\n",
    "#                 return torch.tensor(np.random.choice(env.available_actions))\n",
    "#             else:\n",
    "#                 return torch.argmax(actions)\n",
    "    else:\n",
    "        return torch.tensor(np.random.choice(env.available_actions))\n",
    "#         return torch.randint(0, 5, (1,))[0]\n",
    "\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "   \n",
    "    non_final_next_states = torch.reshape(non_final_next_states,(int(non_final_next_states.shape[0]/2), 160))\n",
    "    \n",
    "    \n",
    "    state_batch = torch.reshape(torch.cat(batch.state),(BATCH_SIZE, 160))\n",
    "    action_batch = torch.reshape(torch.stack(batch.action), (BATCH_SIZE,1))\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values.float(), expected_state_action_values.unsqueeze(1).float())\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]C:\\Users\\marti\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:36<00:00, 27.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "\n",
    "episode_predicted_networks = []\n",
    "episode_best_true_networks = []\n",
    "episode_true_networks_r2 = []\n",
    "episode_rewards = []\n",
    "episode_max_possible_rewards = []\n",
    "episode_durations = [] \n",
    "\n",
    "for i_episode in tqdm(range(num_episodes)):\n",
    "    # Initialize the environment and state\n",
    "    env.reset(train=True)\n",
    "        \n",
    "    state = torch.from_numpy(env.current_observation)\n",
    "    \n",
    "    for i in range(80):\n",
    "        #print(state)\n",
    "        action = get_action(state.flatten().unsqueeze(0))\n",
    "        #print(action,i)\n",
    "        _, reward, done, _ = env.step(action)\n",
    "        reward = torch.tensor([reward])\n",
    "\n",
    "        next_state = torch.from_numpy(env.current_observation)\n",
    "        # Observe new state\n",
    "        \n",
    "        if done:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        \n",
    "        success_push = memory.push(state,\n",
    "                    action, \n",
    "                    next_state, \n",
    "                    reward)\n",
    "    \n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model() \n",
    "        \n",
    "        if done:\n",
    "            \n",
    "            episode_predicted_network = env.history_action[-2].numpy()\n",
    "            episode_best_true_network = np.argmax(env.current_rewards)\n",
    "            episode_reward = sum(env.history_rewards)\n",
    "            episode_max_possible_reward = sum(env.history_max_possible_rewards)\n",
    "            \n",
    "            episode_predicted_networks.append(episode_predicted_network)\n",
    "            episode_true_networks_r2.append(env.current_rewards)\n",
    "            episode_best_true_networks.append(episode_best_true_network)\n",
    "            episode_rewards.append(episode_reward)\n",
    "            episode_max_possible_rewards.append(episode_max_possible_reward)\n",
    "            episode_durations.append(i + 1) \n",
    "            \n",
    "            break\n",
    "            \n",
    "        \n",
    "            \n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topk(predicted_network, score_networks, k):\n",
    "    \n",
    "    in_topk = 0\n",
    "    \n",
    "    for predicted, scores in zip(predicted_network,score_networks):\n",
    "        \n",
    "        top_idx = np.argsort(scores)[-k:]\n",
    "        \n",
    "        if predicted in top_idx:\n",
    "            in_topk += 1\n",
    "            \n",
    "    return in_topk/len(predicted_network)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top1: 0.302 , Top 2: 0.694\n"
     ]
    }
   ],
   "source": [
    "top1 = calculate_topk(episode_predicted_networks, episode_true_networks_r2, k=1)\n",
    "top2 = calculate_topk(episode_predicted_networks, episode_true_networks_r2, k=2)\n",
    "print(\"Top1:\", top1,\", Top 2:\", top2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbiElEQVR4nO3de5gkdX3v8ffHBQQERGCNygJLFC+bPF7IghiMEqPIRUVPTMIKcuDREI16TDQq5hgVLxFDYozxgsQQRBNRIyGgGwWSABLkyKIILojZcJENJiwCAbyAC9/zR9VA0/bM9C5TdM3O+/U882xX1a9+9a3q3vl0Vdf8OlWFJEl985BJFyBJ0igGlCSplwwoSVIvGVCSpF4yoCRJvWRASZJ6yYDSgpDkyCQXbOS6+yVZOzC9Osl+c1TXYUnOGpiuJI+bi77b/u5I8vNz1d9Q3+9L8nsD069O8t/tNnfsctvt9t6Z5NNd9T9XkrwoyamTrmM+MqA2EUmuTfLj9pfCLUm+lGSXOer3uXNR44i+7/eLf76oql+oqnNnapNkaRs2m83S199W1f5zUVeSc5O8cqj/barq6rnof2hbi4EjgI+305sDHwD2b7f5g8FtJzk5yXuG+ujstTUpo573qjoD+MUkT55gafOSAbVpeWFVbQM8Gvhv4C8nXE8vzBYSk9LXusZ0JLCyqn7cTv8csCWwemIV9dtngKMnXcR8Y0BtgqrqJ8DfA8um5iV5aJI/TfK99jLMCUm2apftlOSLSW5NcnOSryZ5SJJPAbsCZ7ZnZm8e3tbUWVCSNya5Mcn3kxw123aTPAz4J+Axbd93JHlMexa4U7vu25KsT7JdO/2eJB9sHz88ySlJ1iW5rm37kHbZkUn+LcmfJ7kZeOeIuo9PckGSh49YtlX7jv+WJFcAew0tv/edf5K9k6xKclu7fx9om53f/ntru2/PGFXXNJceD0pydZKb2jqn9ut+l7QG360neS/wK8CH2+19uG1z7yXDMY7ZBe1zdUuSa5IcOHxsBhwInNeu+3jgqoH9/ZfBbSc5GjgMeHNb25nTvbaS7JPkwva1+K0MXEpNsnuS85LcnuRsYKfpikvyiPY1va7dny8mWTLU1/ltX+ck+cjQsZ2pjnOTvLt9Lm9PctbUa5YRz3s7fS5w8AzHU6NUlT+bwA9wLfDc9vHWwCeBUwaWfxA4A9gB2BY4E3hfu+x9wAnA5u3PrwAZ7nea7e4HrAfe1a57EPAj4BFjbHc/YO1Qf+cDv94+Pgv4D+DAgWUvaR+fAvxj2+dS4LvAK9plR7Y1vQ7YDNiqnXcBzZuyvwK+Amw9zT4dB3y1rXkX4NuDdQ4d668BL28fbwPs0z5eChSw2cB609Y10KaAf223vWu7X69sl70T+PRA2/ttg+aX4CuH9qWAx415zH4K/DawCHg1cAPt62DEMVoH7DVdLSO2fTLwnules+30zsAPaF5DDwGe104vHjjWHwAeCjwLuH3weAz1vSPw6zT/F7YFPg+cPrD8a8CfAlsAzwRum+prjDrOpXldPr59Ds8FjpvuOLTzd2jnbzfp3xXz6cczqE3L6UlupfnP9jzgeIAkofnF8/tVdXNV3Q78MXBou95PaS4L7lZVP62qr1b7v2pMPwXe1a67ErgDeMIY2x3lPODZaS5/PRn4UDu9Jc2ZzFeTLAJ+C3hrVd1eVdcCfwa8fKCfG6rqL6tqfd13GWpzmkstO9BcDv3RNDX8JvDetubr2xpm2vfHJdmpqu6oqotmaDtdXcPe3277ezQBv2KWPmc15jG7rqr+qqrupnmD82iaS3ejbE8TEHPpcJrLhiur6p6qOhtYRXNGuSvN8/9HVXVnVZ1P82ZnpGo+A/tCVf2ofd29F3g2wEBfb6+qu6rqApo3UbPWMdDmb6rqu+1z+DngqbPs29Sx2n6cA6GGAbVpeXFVbU/zDvO1wHlJHgUspnkneUl7yeJW4MvtfGiCbA1wVntp6ZgN3O4Pqmr9wPSPaM4mZtvuKOfRnFntCVwOnE3zi2UfYE1V3URzaWcL4LqB9a6jeec75foRfT8OOAQ4tqrumqGGxwytf910DYFX0LyT/k6Si5O8YIa209U1U5vr2noeqHGO2X9NPRgI722m6e8WmjOTubQb8BtTr5X29fJMmqB8DHBLVf1woP20z0uSrZN8vL2UeRvN2ff2bVA/Brh56A3K4DGfqY4p/zXweOr1PpOpY3XrLO00wIDaBFXV3VV1GnA3zX+sm4AfA79QVdu3Pw+v5oYK2nfUb6yqnwdeCLwhya9NdfcASplxu9P0fSHwBOAlwHlVdQXNpa6DaT/zaPv9Kc0vkim7Av85eBhG9H0lcBTwT0meMEPd36e5tDfY90hV9e9VtQJ4JPB+4O/TfL423XEb53gOb/uG9vEPaQJ/yqM2oO9xjtmGuIwmmMc1qrbhedcDnxp4rWxfVQ+rquNonpNHtMd2yrTPC/BGmtfR06tqO5pLggBp+9ohyeCxHDzmM9Uxm+megycB11bVbWP0oZYBtQlK4xDgEcCVVXUPzecuf57kkW2bnZM8v338gvbD7NBcHry7/YHmbsCN+luW2bbb9r1jBm5UaN/VXgK8hvsC6ULgd6am20tQnwPem2TbJLsBbwBm/ZuYqvoM8IfAOUkeO02zzwFvbT9oX0LzmdFISQ5Psrjd11vb2XfTfEZzDxt37N7UbnsX4PXAZ9v5lwLPSrJre8zeOrTetM/VAzlm01hJe8lsTKNqG573aeCFSZ6fZFGSLdPchLOkqq6jucx2bJItkjyT5s3UdLaleXN0a5IdgHdMLRjo651tX88Y6mvaOsbYz+me92fT3BSkDWBAbVrOTHIHTci8F/jfVTV12+9baC7jXdRe8jiH5h0mwB7t9B00Hx5/tO77O5/3AW9rL3X8wUbUNO12q+o7NJ8JXd32P3Up6zyaz4u+PjC9LffdIQVNaPwQuJrm5oe/A04ap6Cq+iTNTR3/kmTpiCbH0lw+uobmRo1PzdDdAcDq9rj/BXBoVf2kDdr3Av/W7ts+49TW+keakL4U+BLw123dZ9OE1WXt8i8OrfcXwEvbu9ZGfW620cdshFNoPhvaasz2fw0sa4/F6e28+7222s/7DqF5A7GO5kzmTdz3e+plwNOBm2kC55QZtvdBmhsYbgIuorm0POgw4Bk0Nz+8h+a43gkwRh3TmuF5X0H7N2Ma39SdWpK0QZL8MXBjVX1w0rU8UEk+C3ynqt4xa+MN7/uFNHd6/uZc972pM6AkLThJ9qI5E7sG2B84HXhGVX1zknXp/ubzX7JL0sZ6FHAazd9LrQVebTj1j2dQkqRe8iYJSVIvzbtLfDvttFMtXbp00mVIkubIJZdcclNV/cwf8M+7gFq6dCmrVq2adBmSpDmSZOSoIF7ikyT1kgElSeolA0qS1EsGlCSplwwoSVIvdRZQSU5K8xXg355meZJ8KMmaJJcl2bOrWiRJ80+XZ1An04z0PJ0DaUbR3gM4GvhYh7VIkuaZzgKq/Urmm2docghwSjUuovm2y0fP0F6StIBM8jOonbn/1yyv5f5fP32vJEcnWZVk1bp16x6U4iRJkzXJkSQyYt7IkWur6kTgRIDly5c7uq0mYukxX5p0CZ269riDJ12CdD+TPINaC+wyML0EuGFCtUiSemaSAXUGcER7N98+wP9U1fcnWI8kqUc6u8SX5DPAfsBOSdYC7wA2B6iqE4CVwEHAGuBHwFFd1SJJmn86C6iqWjHL8gJe09X2JUnzmyNJSJJ6yYCSJPWSASVJ6iUDSpLUSwaUJKmXDChJUi8ZUJKkXjKgJEm9ZEBJknrJgJIk9ZIBJUnqJQNKktRLBpQkqZcMKElSLxlQkqReMqAkSb1kQEmSesmAkiT1kgElSeolA0qS1EsGlCSplwwoSVIvGVCSpF4yoCRJvWRASZJ6yYCSJPWSASVJ6iUDSpLUSwaUJKmXDChJUi8ZUJKkXjKgJEm9ZEBJknqp04BKckCSq5KsSXLMiOUPT3Jmkm8lWZ3kqC7rkSTNH50FVJJFwEeAA4FlwIoky4aavQa4oqqeAuwH/FmSLbqqSZI0f3R5BrU3sKaqrq6qu4BTgUOG2hSwbZIA2wA3A+s7rEmSNE90GVA7A9cPTK9t5w36MPAk4AbgcuD1VXXPcEdJjk6yKsmqdevWdVWvJKlHugyojJhXQ9PPBy4FHgM8Ffhwku1+ZqWqE6tqeVUtX7x48VzXKUnqoS4Dai2wy8D0EpozpUFHAadVYw1wDfDEDmuSJM0TXQbUxcAeSXZvb3w4FDhjqM33gF8DSPJzwBOAqzusSZI0T2zWVcdVtT7Ja4GvAIuAk6pqdZJXtctPAN4NnJzkcppLgm+pqpu6qkmSNH90FlAAVbUSWDk074SBxzcA+3dZgyRpfnIkCUlSLxlQkqReMqAkSb1kQEmSesmAkiT1kgElSeolA0qS1EsGlCSplwwoSVIvGVCSpF4yoCRJvWRASZJ6yYCSJPWSASVJ6iUDSpLUSwaUJKmXDChJUi8ZUJKkXjKgJEm9ZEBJknrJgJIk9ZIBJUnqJQNKktRLBpQkqZcMKElSLxlQkqReMqAkSb1kQEmSesmAkiT1kgElSeolA0qS1EsGlCSplwwoSVIvdRpQSQ5IclWSNUmOmabNfkkuTbI6yXld1iNJmj8266rjJIuAjwDPA9YCFyc5o6quGGizPfBR4ICq+l6SR3ZVjyRpfunyDGpvYE1VXV1VdwGnAocMtXkZcFpVfQ+gqm7ssB5J0jwyVkAl+UKSg5NsSKDtDFw/ML22nTfo8cAjkpyb5JIkR0yz/aOTrEqyat26dRtQgiRpvho3cD5Gc7bz70mOS/LEMdbJiHk1NL0Z8EvAwcDzgT9K8vifWanqxKpaXlXLFy9ePGbJkqT5bKyAqqpzquowYE/gWuDsJBcmOSrJ5tOsthbYZWB6CXDDiDZfrqofVtVNwPnAUzZkByRJm6axL9kl2RE4Engl8E3gL2gC6+xpVrkY2CPJ7km2AA4Fzhhq84/AryTZLMnWwNOBKzdoDyRJm6Sx7uJLchrwROBTwAur6vvtos8mWTVqnapan+S1wFeARcBJVbU6yava5SdU1ZVJvgxcBtwDfKKqvv3AdkmStCkY9zbzT1TVysEZSR5aVXdW1fLpVmrXWTk074Sh6eOB48esQ5K0QIx7ie89I+Z9bS4LkSRp0IxnUEkeRXNr+FZJnsZ9d+ZtB2zdcW2SpAVstkt8z6e5MWIJ8IGB+bcDf9hRTZIkzRxQVfVJ4JNJfr2qvvAg1SRJ0qyX+A6vqk8DS5O8YXh5VX1gxGqSJD1gs13ie1j77zZdFyJJ0qDZLvF9vP332AenHEmSGuMOFvsnSbZLsnmSf05yU5LDuy5OkrRwjft3UPtX1W3AC2jGz3s88KbOqpIkLXjjBtTUgLAHAZ+pqps7qkeSJGD8oY7OTPId4MfA7yZZDPyku7IkSQvduF+3cQzwDGB5Vf0U+CE/++24kiTNmXHPoACeRPP3UIPrnDLH9UiSBIz/dRufAh4LXArc3c4uDChJUkfGPYNaDiyrquGvbJckqRPj3sX3beBRXRYiSdKgcc+gdgKuSPJ14M6pmVX1ok6qkiQteOMG1Du7LEKSpGFjBVRVnZdkN2CPqjonydbAom5LkyQtZOOOxffbwN8DH29n7Qyc3lFNkiSNfZPEa4B9gdsAqurfgUd2VZQkSeMG1J1VddfURPvHut5yLknqzLgBdV6SPwS2SvI84PPAmd2VJUla6MYNqGOAdcDlwO8AK4G3dVWUJEnj3sV3T5LTgdOral23JUmSNMsZVBrvTHIT8B3gqiTrkrz9wSlPkrRQzXaJ7/do7t7bq6p2rKodgKcD+yb5/a6LkyQtXLMF1BHAiqq6ZmpGVV0NHN4ukySpE7MF1OZVddPwzPZzqM1HtJckaU7MFlB3beQySZIekNnu4ntKkttGzA+wZQf1SJIEzBJQVeWAsJKkiRj3D3UlSXpQdRpQSQ5IclWSNUmOmaHdXknuTvLSLuuRJM0fnQVUkkXAR4ADgWXAiiTLpmn3fuArXdUiSZp/ujyD2htYU1VXtyOhnwocMqLd64AvADd2WIskaZ7pMqB2Bq4fmF7bzrtXkp2BlwAnzNRRkqOTrEqyat06hwKUpIWgy4DKiHnD3yH1QeAtVXX3TB1V1YlVtbyqli9evHiu6pMk9dhYo5lvpLXALgPTS4AbhtosB05NArATcFCS9VV1eod1SZLmgS4D6mJgjyS7A/8JHAq8bLBBVe0+9TjJycAXDSdJEnQYUFW1Pslrae7OWwScVFWrk7yqXT7j506SpIWtyzMoqmolzbfvDs4bGUxVdWSXtUiS5hdHkpAk9ZIBJUnqJQNKktRLBpQkqZcMKElSLxlQkqReMqAkSb1kQEmSesmAkiT1kgElSeolA0qS1EsGlCSplwwoSVIvGVCSpF4yoCRJvWRASZJ6yYCSJPWSASVJ6iUDSpLUSwaUJKmXDChJUi8ZUJKkXjKgJEm9ZEBJknrJgJIk9ZIBJUnqJQNKktRLBpQkqZcMKElSLxlQkqReMqAkSb1kQEmSesmAkiT1UqcBleSAJFclWZPkmBHLD0tyWftzYZKndFmPJGn+6CygkiwCPgIcCCwDViRZNtTsGuDZVfVk4N3AiV3VI0maX7o8g9obWFNVV1fVXcCpwCGDDarqwqq6pZ28CFjSYT2SpHmky4DaGbh+YHptO286rwD+adSCJEcnWZVk1bp16+awRElSX3UZUBkxr0Y2TH6VJqDeMmp5VZ1YVcuravnixYvnsERJUl9t1mHfa4FdBqaXADcMN0ryZOATwIFV9YMO65EkzSNdnkFdDOyRZPckWwCHAmcMNkiyK3Aa8PKq+m6HtUiS5pnOzqCqan2S1wJfARYBJ1XV6iSvapefALwd2BH4aBKA9VW1vKuaJEnzR5eX+KiqlcDKoXknDDx+JfDKLmuQJM1PjiQhSeolA0qS1EsGlCSplwwoSVIvGVCSpF4yoCRJvWRASZJ6yYCSJPWSASVJ6iUDSpLUSwaUJKmXDChJUi8ZUJKkXjKgJEm9ZEBJknrJgJIk9ZIBJUnqJQNKktRLBpQkqZcMKElSLxlQkqReMqAkSb1kQEmSesmAkiT1kgElSeolA0qS1EsGlCSplwwoSVIvGVCSpF4yoCRJvWRASZJ6yYCSJPWSASVJ6qVOAyrJAUmuSrImyTEjlifJh9rllyXZs8t6JEnzR2cBlWQR8BHgQGAZsCLJsqFmBwJ7tD9HAx/rqh5J0vyyWYd97w2sqaqrAZKcChwCXDHQ5hDglKoq4KIk2yd5dFV9v8O6NIOlx3xp0iV06trjDp50CZLG1GVA7QxcPzC9Fnj6GG12Bu4XUEmOpjnDArgjyVVzW2rndgJumnQRPfWgHpu8/8Ha0pzw2EzP/1OjzdfjstuomV0GVEbMq41oQ1WdCJw4F0VNQpJVVbV80nX0kcdmeh6b6XlsRtvUjkuXN0msBXYZmF4C3LARbSRJC1CXAXUxsEeS3ZNsARwKnDHU5gzgiPZuvn2A//HzJ0kSdHiJr6rWJ3kt8BVgEXBSVa1O8qp2+QnASuAgYA3wI+CoruqZsHl7efJB4LGZnsdmeh6b0Tap45LmBjpJkvrFkSQkSb1kQEmSesmA6thswz0tVElOSnJjkm9PupY+SbJLkn9NcmWS1UleP+ma+iLJlkm+nuRb7bE5dtI19U2SRUm+meSLk65lLhhQHRpzuKeF6mTggEkX0UPrgTdW1ZOAfYDX+Jq5153Ac6rqKcBTgQPau391n9cDV066iLliQHXr3uGequouYGq4pwWvqs4Hbp50HX1TVd+vqm+0j2+n+WWz82Sr6odq3NFObt7+eJdXK8kS4GDgE5OuZa4YUN2abignaVZJlgJPA/7fhEvpjfYS1qXAjcDZVeWxuc8HgTcD90y4jjljQHVrrKGcpGFJtgG+APxeVd026Xr6oqrurqqn0ow6s3eSX5xwSb2Q5AXAjVV1yaRrmUsGVLccykkbLMnmNOH0t1V12qTr6aOquhU4Fz/HnLIv8KIk19J8lPCcJJ+ebEkPnAHVrXGGe5LulSTAXwNXVtUHJl1PnyRZnGT79vFWwHOB70y0qJ6oqrdW1ZKqWkrze+ZfqurwCZf1gBlQHaqq9cDUcE9XAp+rqtWTraofknwG+BrwhCRrk7xi0jX1xL7Ay2neAV/a/hw06aJ64tHAvya5jObN39lVtUncTq3RHOpIktRLnkFJknrJgJIk9ZIBJUnqJQNKktRLBpQkqZcMKC0YSV6SpJI8cSPWvTbJTiPmv2hqlPokL97YgV2TbJ/kdzdm3TH7f1eS527gOiP3WXqwGFBaSFYAF9D8IePPaEef3yBVdUZVHddOvphm1PqNsT2wwQE1bs1V9faqOmdD+5cmyYDSgtCObbcv8AoGAirJfu33L/0dcHk7GOmfJrk8yWVJXjfQzeuSfKNd9sR2/SOTfDjJLwMvAo5v/7j2se3Pl5NckuSrA+v8XJJ/aL/X6FvtuscBj23XPb6t64sDdX44yZHt42uTvD3JBcBvJNk/ydfa2j7f7uvw/p+c5KUD6x87Yl92THJW+31CH2dgLMkkh7ffxXRpko+3x2mv9hhtmeRh7Xc0OTae5owBpYXixcCXq+q7wM1J9hxYtjfwf6tqGXA0sDvwtKp6MvC3A+1uqqo9gY8BfzDYeVVdSDOM1Zuq6qlV9R/AicDrquqX2vYfbZt/CDiv/V6jPYHVwDHAf7TrvmmM/flJVT0TOAd4G/DctrZVwBvGWH/UvrwDuKCqntbuy64ASZ4E/BawbztQ693AYVV1cdvuPcCfAJ+uKr+AUnNms0kXID1IVtB8HQE0g2muAL7RTn+9qq5pHz8XOKEdpoqqGvzOqqmBWy8B/tdMG2vPYn4Z+HwzvB4AD23/fQ5wRNv/3cD/JHnEBu7PZ9t/96G5rPhv7Xa2oBlCajaj9uVZU4+r6ktJbmnn/xrwS8DF7Ta2ovm6C4B30Qw79BPg/2zgPkgzMqC0yUuyI00o/GKSAhYBleTNbZMfDjZn+q9EubP9925m/7/zEODW9oxjY6zn/lc4thxaPlVzaMakW7GB/U+3L6P2PcAnq+qtI5btAGxD8+WBW3L/Yyk9IF7i00LwUuCUqtqtqpZW1S7ANcAzR7Q9C3hVks0AkuywAdu5HdgWoP0Op2uS/EbbT5I8pW33z8Cr2/mLkmw3uG7rOmBZkocmeTjNWcwoFwH7Jnlc29/WSR6/ATUPOh84rO3nQGDqrO6fgZcmeWS7bIcku7XLTgT+iOZS6Ps3crvSSAaUFoIVwD8MzfsC8LIRbT8BfA+4LMm3pmkznVOBN7U3GTyW5pf9K9p+VgOHtO1eD/xqkstpLrH9QlX9gOYy3beTHF9V1wOfAy6j+eX/zVEbrKp1wJHAZ9pRvi8CNvg2+taxwLOSfAPYn+Y4UFVX0HzOdVa7jbOBRyc5AlhfVX9Hc5PHXkmes5Hbln6Go5lLknrJMyhJUi8ZUJKkXjKgJEm9ZEBJknrJgJIk9ZIBJUnqJQNKktRL/x/KiEV2/g94xQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(episode_predicted_networks)\n",
    "\n",
    "plt.bar(x = list(range(5)), height=np.bincount(np.array(episode_predicted_networks), minlength=5)/len(episode_predicted_networks))\n",
    "plt.title(\"Best network distribution (fitted agent)\")\n",
    "plt.xlabel(\"Architecture index\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./figures/arch_distribution-predict.pdf\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.available_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "filter_size = 11\n",
    "pad = int((filter_size - 1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_steps = np.linspace(0, num_episodes -1, num= num_episodes, dtype = int)\n",
    "plt.plot(x_steps, np.array(episode_max_possible_rewards) - np.array(episode_rewards), label=\"regret\")\n",
    "plt.plot(x_steps[pad:-pad], moving_average(np.array(episode_max_possible_rewards) - np.array(episode_rewards), filter_size), label=\"Mean regret (smoothed)\")\n",
    "envtype = \"random\" if SHUFFLE_SAMPLES else \"sequential\"\n",
    "plt.title(f\"DQN ({envtype} samples)\")\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Mean regret\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"./figures/regret-DQN-{envtype}.pdf\", dpi=1000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_steps, episode_durations,c='orange', label=\"Duration in steps\")\n",
    "plt.plot(x_steps[pad:-pad], moving_average(episode_durations, filter_size), label=\"Duration (smoothed)\")\n",
    "envtype = \"random\" if SHUFFLE_SAMPLES else \"sequential\"\n",
    "plt.title(f\"DQN ({envtype} samples)\")\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Episode length\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"./figures/duration-DQN-{envtype}.pdf\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
